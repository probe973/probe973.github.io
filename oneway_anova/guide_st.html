<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>One-way ANOVA using Stata</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        /* Merged Styles */
        body {
            font-family: 'Inter', sans-serif;
            margin: 0;
            padding: 0;
            color: #222;
            background-color: #f8f8f8;
            line-height: 1.6;
        }
        .container {
            padding: 25px;
            max-width: 960px;
            margin: 30px auto;
            background-color: white;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            border-radius: 10px;
        }
        h1 {
            color: #004085;
            border-bottom: 3px solid #004085;
            padding-bottom: 10px;
            margin-bottom: 20px;
            font-size: 2.2em;
        }
        h2 {
            color: #004085;
            margin-top: 35px;
            font-size: 1.8em;
            border-bottom: 2px solid #eee;
            padding-bottom: 5px;
        }
        h3 {
            color: #0056b3;
            font-size: 1.2em;
            border-bottom: 1px solid #eee;
            margin-top: 25px;
        }
        h4 {
            color: #0056b3;
            font-size: 1em;
            margin-top: 25px;
        }
        .subtitle {
            color: #444;
            font-size: 1.2em;
            margin-bottom: 25px;
        }
        code {
            background-color: #eef;
            padding: 2px 4px;
            border-radius: 4px;
            font-family: "Courier New", Courier, monospace;
            color: #c00;
        }
        pre {
            background-color: #eef;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: "Courier New", Courier, monospace;
            color: #333;
            border: 1px solid #ddd;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        table, th, td {
            border: 1px solid #ddd;
        }
        th, td {
            padding: 10px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
            color: #333;
            font-weight: bold;
        }
        ul {
            list-style-type: disc;
            margin-left: 20px;
            margin-bottom: 1em; /* Added for consistent spacing */
        }
        ol {
            list-style-type: decimal;
            margin-left: 20px;
            margin-bottom: 1em; /* Added for consistent spacing */
        }
        li {
            margin-bottom: 0.5em; /* Added for spacing between list items */
        }
        p {
            margin-bottom: 1em; /* Added for consistent paragraph spacing */
        }
        .reflection-question {
            background-color: #f0f8ff;
            border-left: 5px solid #add8e6;
            padding: 10px 15px;
            margin: 15px 0;
        }
        .write-up-template {
            background-color: #e9f5e9;
            border-left: 5px solid #4CAF50;
            padding: 15px;
            margin: 20px 0;
        }
        .write-up-template p {
            margin-bottom: 10px;
        }
        .solution-section {
            background-color: #f0fff0;
            border-left: 5px solid #6b8e23;
            padding: 10px 15px;
            margin: 15px 0;
        }
        .solution-section h4 {
            color: #6b8e23;
        }
        .top-nav {
            display: flex;
            justify-content: flex-start;
            gap: 15px;
            padding: 15px;
            background-color: #004085;
            border-bottom-left-radius: 10px;
            border-bottom-right-radius: 10px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            align-items: center;
            position: sticky;
            top: 0;
            width: 100%;
            z-index: 1000;
            flex-wrap: wrap;
        }
        .top-nav span {
            color: white;
            font-weight: bold;
            margin-right: 5px;
        }
        .top-nav a {
            color: white;
            padding: 8px 15px;
            border-radius: 20px;
            text-decoration: none;
            font-weight: bold;
            transition: background-color 0.3s ease, transform 0.2s ease;
            white-space: nowrap;
            background-color: rgba(255, 255, 255, 0.2);
        }
        .top-nav a:hover {
            background-color: rgba(255, 255, 255, 0.4);
            transform: translateY(-1px);
        }
        .button-group {
            display: flex;
            flex-wrap: nowrap;
            gap: 15px;
            margin-top: 20px;
            justify-content: center;
        }
        .button-group a {
            background-color: #004085;
            color: white;
            padding: 14px 25px;
            border-radius: 30px;
            text-decoration: none;
            text-align: center;
            flex-grow: 1;
            flex-basis: 0;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
            transition: background-color 0.3s ease, transform 0.2s ease;
            font-weight: bold;
            letter-spacing: 0.5px;
            white-space: nowrap;
        }
        .button-group a:hover {
            background-color: #002c5a;
            transform: translateY(-2px);
        }
        hr {
            border: 0;
            height: 2px;
            background: #e0e0e0;
            margin: 40px 0;
        }
    </style>
</head>
<body>
    <div class="top-nav">
        <span>Links to:</span>
        <a href="../index.html">Home</a>
        <a href="../stata.html">Stata Guides</a>
    </div>
    <div class="container">
        <h1>One-way ANOVA using Stata</h1>
        <p class="subtitle">A Guide to Understanding and Performing ANOVA with Stata</p>

        <p>ANOVA is an abbreviation of Analysis of Variance. It can be used to <strong>determine if there are statistically significant differences between the means of three or more independent (unrelated) groups on a continuous dependent variable.</strong> While it shares a goal with the independent-samples t-test (comparing means), ANOVA is specifically designed for situations with more than two groups, helping to avoid the increased risk of Type I errors that would arise from performing multiple t-tests. A one-way ANOVA is used to determine whether there are differences in a measure variable based on a single categorical factor. This factor can have more than two levels, unlike the independent-samples t-test where there could only be two. Some examples of where a one-way ANOVA could be used include:</p>
        <ul>
            <li>Comparing the effectiveness of three different teaching methods (e.g., traditional lecture, blended learning, flipped classroom) on student exam scores.</li>
            <li>Assessing if anxiety levels differ among people with mild, moderate, and severe depression.</li>
            <li>Investigating if plant growth varies significantly under three different fertilizer types.</li>
        </ul>
        <p>In this guide we will go over performing a one-way ANOVA to determine the following:</p>
        <ul>
            <li>Does preferred study method (flashcards, practice tests, summarising) make a difference to final examination score?</li>
            <li>Does study session group (low, medium, high number of sessions) make a difference to the study session score?</li>
        </ul>
        <p>You will be making using of the `omni.dta` dataset, which has been used throughout all these guides. Please make sure you have downloaded the data and loaded into Stata.</p>

        <h2>Assumptions of a One-way ANOVA</h2>
        <p>For a one-way ANOVA, there are several key assumptions that should ideally be met for the results to be reliable. It's important to check these before interpreting your ANOVA output:</p>
        <ol>
            <li><strong>Independence of Observations:</strong> The observations within each group must be independent of each other. This means that the data points in one group should not be related to or influenced by data points in another group, or within the same group. This is typically ensured by the study design (e.g., participants are randomly assigned to groups, or each participant provides only one data point).</li>
            <li><strong>Normality:</strong> The dependent variable should be approximately normally distributed for each group. While ANOVA is robust to minor violations of normality, particularly with larger sample sizes, severe non-normality can affect the validity of the p-value.
                <ul>
                    <li><strong>How to check:</strong> In Stata, you can assess normality using commands like `swilk` (Shapiro-Wilk test) after `sort`ing and `by`ing groups, or visually inspect histograms with `histogram dependent_variable, by(independent_variable) normal`.</li>
                </ul>
            </li>
            <li><strong>Homogeneity of Variances (Homoscedasticity):</strong> The variance of the dependent variable should be approximately equal across all groups. This means that the spread of data points around the mean should be similar in each group.
                <ul>
                    <li><strong>How to check:</strong> The most common test for this assumption is Levene's test, which can be performed using the `robvar` command in Stata (may require installation: `ssc install robvar`).</li>
                </ul>
            </li>
        </ol>
        <p>The assumption of normality of normality has been passed for the variables we are looking at today.</p>
        <div class="reflection-question">
            <h4>Task:</h4>
            <p>Check the assumption of normality for these variables. You can use <a href="../assessing_normality_of_data/guide_st.html">this earlier guide</a> if you want to review this.</p>
        </div>

        <h2>Null and Alternative Hypotheses</h2>
        <p>The null hypothesis (H<sub>0</sub>) of a one-way ANOVA is that the mean score for all groups will be the same.</p>
        <p style="text-align: center;">H<sub>0</sub>: &#x03BC;<sub>1</sub> = &#x03BC;<sub>2</sub> = &#x03BC;<sub>3</sub> = &hellip; = &#x03BC;<sub>k</sub></p>
        <p>(where &#x03BC; represents the mean, and k is the number of groups)</p>
        <p>The alternative hypothesis (H<sub>1</sub>) is that there is a difference in the mean score between some, or all, of the groups.</p>
        <p style="text-align: center;">H<sub>1</sub>: Not all means are equal</p>
        <p>The ANOVA is carried out and produces an F statistic and a p-value. If this p-value is less than a defined amount, normally 0.05 is used, then this gives evidence of there being a difference between the groups. If this is not the case then we have not found enough evidence that the groups make a difference to the score.</p>

        <h2>One-way ANOVA procedure in Stata for final examination score by study method</h2>
        <h3>Procedure for final examination score by study method</h3>
        <p>To conduct a One-Way ANOVA in Stata for `final_exam_score` by `preferred_study_method`, follow these steps:</p>
        <ol>
            <li>Load your `omni.dta` dataset into Stata. If the file is in your working directory, use the `use` command.
                <pre><code>use omni.dta, clear</code></pre>
                The `clear` option clears any data currently in memory before loading the new dataset.
                <br>
                (Menu driven alternative) Go to <strong>File &gt; Open...</strong>, then navigate to your `omni.dta` file and click "Open".
            </li>

            <li>Check the homogeneity of variances using Levene's Test. You can use the `robvar` command. If you don't have it installed, Stata will prompt you to install it (type `ssc install robvar` in the command window). The syntax is `robvar dependent_variable, by(grouping_variable)`.
                <pre><code>robvar final_exam_score, by(preferred_study_method)</code></pre>
                (Menu driven alternative) Go to <strong>Statistics &gt; Summaries, tables, and tests &gt; Tables of means, medians, and modes &gt; Equality of variances test</strong>. In the dialog box, select `final_exam_score` for "Variable", `preferred_study_method` for "By variable", and click "OK".
            </li>

            <li>Perform the One-Way ANOVA using the `oneway` command. The basic syntax is `oneway dependent_variable independent_variable`. Include the `tabulate` option to display a table of descriptive statistics (mean, standard deviation, and count) for each group. After running the `oneway` command, use `estat esize, eta` to display effect sizes, specifically Eta-squared (`eta`). This `estat` command is available in Stata 16 and newer.
                <pre><code>oneway final_exam_score preferred_study_method, tabulate
estat esize, eta</code></pre>
                <br>
                (Menu driven alternative) Go to <strong>Statistics &gt; ANOVA/MANOVA &gt; One-way ANOVA</strong>. In the dialog box:
                <ul>
                    <li>In the "Response variable:" field, select `final_exam_score`.</li>
                    <li>In the "Factor variable:" field, select `preferred_study_method`.</li>
                    <li>Check the "Display summary statistics" box under "Output".</li>
                    <li>To get effect sizes, click on the "Effect sizes" tab (if available in your Stata version, e.g., Stata 16+), and select "Eta squared".</li>
                    <li>Click <strong>OK</strong>.</li>
                </ul>
            </li>
        </ol>

        <p>The following results are given:</p>
        <h4>Levene&rsquo;s Test for Homogeneity of Variances</h4>
        <p>The output for Levene's Test from Stata's `robvar` command will look similar to this. The "Prob > F" column gives the p-value.</p>
        <pre><code>Robust variance estimates
Levene's W0 =      1.30
     Prob > F =    0.2760</code></pre>
        <table>
            <thead>
                <tr>
                    <th></th>
                    <th>Levene Statistic</th>
                    <th>df1</th>
                    <th>df2</th>
                    <th>Prob &gt; F</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>final_exam_score</td>
                    <td>1.304</td>
                    <td>2</td>
                    <td>97</td>
                    <td>0.276</td>
                </tr>
            </tbody>
        </table>
        <p>Here's how to interpret these numbers:</p>
        <ul>
            <li>The <strong>Levene Statistic (W0 or F)</strong> is 1.304.</li>
            <li>The <strong>degrees of freedom (df1 and df2)</strong> are 2 and 97, respectively.</li>
            <li>The <strong>Prob &gt; F (p-value)</strong> is 0.276.</li>
        </ul>
        <p>Since the p-value for Levene&rsquo;s test (0.276) is greater than our typical alpha level of 0.05, we do not reject the null hypothesis of Levene&rsquo;s test. This indicates that <strong>the assumption of equality of variances has been met</strong>. Therefore, for the main ANOVA, you should interpret the results from the standard F-test. If the p-value had been less than 0.05 (indicating violation of homogeneity), you would typically use <strong>Welch's ANOVA</strong> instead of the standard ANOVA. Welch's ANOVA does not assume equal variances. You can perform it in Stata using the `oneway` command with the `welch` option:</p>
        <pre><code>oneway final_exam_score preferred_study_method, welch</code></pre>

        <h4>Descriptive Statistics</h4>
        <p>The `oneway` command with the `tabulate` option will produce a table of summary statistics for each group:</p>
        <pre><code>                  |    Summary of final_exam_score
preferred_study_method |        Mean   Std. Dev.       Freq.
-----------------------+------------------------------------
Flashcards             |    75.64444    6.450419          36
Practice Tests         |    74.45161    5.353382          31
Summarizing            |    73.93939    5.356236          33
-----------------------+------------------------------------
Total                  |      74.71     5.762149         100</code></pre>
        <table>
            <thead>
                <tr>
                    <th>preferred_study_method</th>
                    <th>N</th>
                    <th>Mean</th>
                    <th>Std. Deviation</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Flashcards</td>
                    <td>36</td>
                    <td>75.64</td>
                    <td>6.450</td>
                </tr>
                <tr>
                    <td>Practice Tests</td>
                    <td>31</td>
                    <td>74.45</td>
                    <td>5.353</td>
                </tr>
                <tr>
                    <td>Summarizing</td>
                    <td>33</td>
                    <td>73.94</td>
                    <td>5.356</td>
                </tr>
            </tbody>
        </table>
        <p>From this table, you can see the mean final exam scores for students who used Flashcards (75.64), Practice Tests (74.45), and Summarizing (73.94).</p>

        <h4>ANOVA Results</h4>
        <p>The `oneway` command output will display the core ANOVA table:</p>
        <pre><code>                  Analysis of Variance
    Source |  Partial SS    df       MS      F     Prob > F
-------------+------------------------------------------------
preferred_st~|    52.72803     2  26.36402   0.79   0.4560
    Residual |  3233.86197    97  33.33878
-------------+------------------------------------------------
       Total |  3286.59000    99  33.20000</code></pre>
        <table>
            <thead>
                <tr>
                    <th></th>
                    <th>Sum of Squares</th>
                    <th>df</th>
                    <th>Mean Square</th>
                    <th>F</th>
                    <th>Prob &gt; F</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Between Groups</td>
                    <td>52.728</td>
                    <td>2</td>
                    <td>26.364</td>
                    <td>0.791</td>
                    <td>0.456</td>
                </tr>
                <tr>
                    <td>Within Groups</td>
                    <td>3233.862</td>
                    <td>97</td>
                    <td>33.339</td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Total</td>
                    <td>3286.590</td>
                    <td>99</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
            </tbody>
        </table>
        <p>Here's what these values mean:</p>
        <ul>
            <li><strong>F (0.791):</strong> This is the F-statistic, which is the test statistic for ANOVA.</li>
            <li><strong>df (2, 97):</strong> These are the degrees of freedom. The "df" for `preferred_study_method` (between groups) is 2, and the "df" for Residuals (within groups) is 97.</li>
            <li><strong>Prob &gt; F (0.456):</strong> This is the p-value associated with the F-statistic.</li>
        </ul>

        <div class="reflection-question">
            <h4>Question:</h4>
            <p>Is there evidence that the study method makes a difference to the final exam grade?</p>
            <h4>Answer:</h4>
            <p>Based on the ANOVA results, there is no statistically significant evidence that the preferred study method makes a difference to the final exam grade. The p-value obtained is 0.456, which is greater than the conventional significance level of 0.05. Therefore, we do not reject the null hypothesis, meaning we do not have sufficient evidence to conclude that there is a significant difference in final exam scores between the different study methods.</p>
        </div>

        <h2>Effect Size</h2>
        <p>Effect Size is a measure of the magnitude of the difference or relationship between variables, independent of sample size. For ANOVA, a common effect size measure is <strong>Eta Squared (&eta;<sup>2</sup>)</strong>. It represents the proportion of the total variance in the dependent variable that is accounted for by the independent variable (the grouping factor).</p>
        <ul>
            <li><strong>Interpretation of Eta Squared (&eta;<sup>2</sup>):</strong>
                <ul>
                    <li><strong>Small Effect:</strong> &eta;<sup>2</sup> = 0.01 (meaning 1% of the variance in the dependent variable is explained by the independent variable)</li>
                    <li><strong>Medium Effect:</strong> &eta;<sup>2</sup> = 0.06 (meaning 6% of the variance is explained)</li>
                    <li><strong>Large Effect:</strong> &eta;<sup>2</sup> = 0.14 (meaning 14% of the variance is explained)</li>
                </ul>
            </li>
        </ul>
        <p>In Stata 16 and newer, you can obtain Eta Squared using the `estat esize` post-estimation command after running `oneway`.</p>

        <h3>Procedure to obtain Eta Squared (&eta;<sup>2</sup>) in Stata:</h3>
        <p>After you have run your `oneway` command, use the `estat esize` command with the `eta` option. This will display a table including Eta-squared and its confidence interval.</p>
        <pre><code>estat esize, eta</code></pre>
        <p>(Menu driven alternative for `estat esize`) After running your `oneway` command, go to <strong>Statistics &gt; Postestimation</strong>. In the Postestimation Selector, under "Tests and contrasts of parameters", find "Effect sizes" and select "Eta squared". Then click "Launch".</p>
        <h4>Effect Sizes for One-Way ANOVA</h4>
        <p>The output from `estat esize, eta` will look similar to this in your Stata Results window:</p>
        <pre><code>. estat esize, eta

Effect sizes for one-way ANOVA

----------------------------------------------------------------------
             Source |       esize   [95% conf. interval]
--------------------+------------------------------------------------
 preferred_st~method |    0.016029    0.000000    0.080004
--------------------+------------------------------------------------
Note: Obs. = 100. Eta-squared is computed.</code></pre>
        <table>
            <thead>
                <tr>
                    <th>Source</th>
                    <th>esize</th>
                    <th colspan="2">95% conf. interval</th>
                </tr>
                <tr>
                    <th></th>
                    <th></th>
                    <th>Lower</th>
                    <th>Upper</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>preferred_study_method</td>
                    <td>0.016</td>
                    <td>0.000</td>
                    <td>0.080</td>
                </tr>
            </tbody>
        </table>
        <p>The effect size, &eta;<sup>2</sup>, is found in the "esize" column for `preferred_study_method`. In this case, &eta;<sup>2</sup> = 0.016.</p>

        <div class="reflection-question">
            <h4>Question:</h4>
            <p>What is the size of the effect of study method on final examination score?</p>
            <h4>Answer:</h4>
            <p>The size of the effect of study method on final examination score, as measured by Eta Squared (&eta;<sup>2</sup>), is 0.016. According to Cohen's guidelines for interpreting effect sizes, an &eta;<sup>2</sup> of 0.01 is considered a small effect. Therefore, an &eta;<sup>2</sup> of 0.016 indicates a very small practical effect, meaning that preferred study method accounts for only 1.6% of the variance in final examination scores.</p>
        </div>

        <h2>Write-up Results</h2>
        <p>Here's an example write-up of these results:</p>
        <div class="write-up-template">
            <p>A one-way ANOVA was conducted to examine the effect of preferred study method (Flashcards, Practice Tests, Summarizing) on final examination scores. Levene's test indicated that the assumption of homogeneity of variances was met, <i>F</i>(2, 97) = 1.30, <i>p</i> = 0.276. The ANOVA results showed that there was no statistically significant effect of preferred study method on final examination score, <i>F</i>(2, 97) = 0.791, <i>p</i> = 0.456. The effect size, as measured by Eta Squared, was &eta;<sup>2</sup> = 0.016, which indicates a very small effect, accounting for only 1.6% of the variance in final examination scores. Descriptive statistics revealed that students using Flashcards had a mean score of 75.64 (<i>M</i> = 75.64, <i>SD</i> = 6.45), Practice Tests a mean of 74.45 (<i>M</i> = 74.45, <i>SD</i> = 5.35), and Summarizing a mean of 73.94 (<i>M</i> = 73.94, <i>SD</i> = 5.36).</p>
        </div>

        <hr>

        <h2>One-way ANOVA procedure in Stata for study session score by study session group</h2>
        <h3>Procedure for study session score by study session group</h3>
        <div class="reflection-question">
            <h4>Task:</h4>
            <p>Use the previous part of the guide to conduct a one-way ANOVA to determine whether the study session group makes a difference to the study session score.</p>
        </div>
        <p>To perform this analysis in Stata, follow the same steps as detailed for the `final_exam_score` analysis, but substitute the variables:</p>
        <ol>
            <li>Check the homogeneity of variances using `robvar`.
                <pre><code>robvar study_session_score, by(study_session_group)</code></pre>
                (Menu driven alternative) Go to <strong>Statistics &gt; Summaries, tables, and tests &gt; Tables of means, medians, and modes &gt; Equality of variances test</strong>. In the dialog box, select `study_session_score` for "Variable", `study_session_group` for "By variable", and click "OK".
            </li>
            <li>Perform the One-Way ANOVA using the `oneway` command. We'll include the `tabulate` option for descriptive statistics and use `estat esize, eta` afterwards for effect sizes.
                <pre><code>oneway study_session_score study_session_group, tabulate
estat esize, eta</code></pre>
                (Menu driven alternative) Go to <strong>Statistics &gt; ANOVA/MANOVA &gt; One-way ANOVA</strong>. In the dialog box:
                <ul>
                    <li>In the "Response variable:" field, select `study_session_score`.</li>
                    <li>In the "Factor variable:" field, select `study_session_group`.</li>
                    <li>Check the "Display summary statistics" box under "Output".</li>
                    <li>To get effect sizes, click on the "Effect sizes" tab (if available in your Stata version, e.g., Stata 16+), and select "Eta squared".</li>
                    <li>Click <strong>OK</strong>.</li>
                </ul>
            </li>
        </ol>

        <p>The results will be:</p>
        <h4>Levene&rsquo;s Test for Homogeneity of Variances</h4>
        <pre><code>Robust variance estimates
Levene's W0 =      0.16
     Prob > F =    0.8520</code></pre>
        <table>
            <thead>
                <tr>
                    <th></th>
                    <th>Levene Statistic</th>
                    <th>df1</th>
                    <th>df2</th>
                    <th>Prob &gt; F</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>study_session_score</td>
                    <td>0.160</td>
                    <td>2</td>
                    <td>97</td>
                    <td>0.852</td>
                </tr>
            </tbody>
        </table>

        <h4>ANOVA - study_session_score</h4>
        <pre><code>                  Analysis of Variance
    Source |  Partial SS    df       MS      F     Prob > F
-------------+------------------------------------------------
study_sessio~|  2833.53000     2  1416.765   66.00   0.0000
    Residual |  2082.47000    97  21.46876
-------------+------------------------------------------------
       Total |  4916.00000    99  49.65657</code></pre>
        <table>
            <thead>
                <tr>
                    <th></th>
                    <th>Sum of Squares</th>
                    <th>df</th>
                    <th>Mean Square</th>
                    <th>F</th>
                    <th>Prob &gt; F</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Between Groups</td>
                    <td>2833.530</td>
                    <td>2</td>
                    <td>1416.765</td>
                    <td>65.992</td>
                    <td>&lt;.001</td>
                </tr>
                <tr>
                    <td>Within Groups</td>
                    <td>2082.470</td>
                    <td>97</td>
                    <td>21.469</td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Total</td>
                    <td>4916.000</td>
                    <td>99</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
            </tbody>
        </table>

        <h4>Descriptive Statistics</h4>
        <pre><code>                  |    Summary of study_session_score
study_session_group |        Mean   Std. Dev.       Freq.
--------------------+------------------------------------
High                |    71.70968    4.692348          31
Low                 |    59.33333    4.708316          33
Medium              |    69.41667    4.513417          36
--------------------+------------------------------------
Total               |    66.8       7.047196         100</code></pre>
        <table>
            <thead>
                <tr>
                    <th>study_session_group</th>
                    <th>N</th>
                    <th>Mean</th>
                    <th>Std. Deviation</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>High</td>
                    <td>31</td>
                    <td>71.71</td>
                    <td>4.692</td>
                </tr>
                <tr>
                    <td>Low</td>
                    <td>33</td>
                    <td>59.33</td>
                    <td>4.708</td>
                </tr>
                <tr>
                    <td>Medium</td>
                    <td>36</td>
                    <td>69.42</td>
                    <td>4.513</td>
                </tr>
            </tbody>
        </table>

        <h3>Interpretation of key results.</h3>
        <p>Here's an interpretation of the key results for `study_session_score` by `study_session_group`:</p>
        <ul>
            <li><strong>Homogeneity of Variances (Levene's Test):</strong> The p-value for Levene's test is 0.852. Since this value is greater than 0.05, the assumption of homogeneity of variances is met. This means you should interpret the results from the standard F-test. If the assumption had been violated, you would typically report <strong>Welch's ANOVA</strong> results, obtained using the `oneway` command with the `welch` option:
                <pre><code>oneway study_session_score study_session_group, welch</code></pre>
            </li>
            <li><strong>ANOVA Results:</strong> The "ANOVA" table shows an F-statistic of 65.992 with <i>df</i>1 = 2 and <i>df</i>2 = 97, and a p-value of &lt;.001. Since the p-value is less than 0.05, there is a statistically significant effect of `study_session_group` on `study_session_score`. This indicates that there are significant differences in study session scores between at least some of the study session groups.</li>
            <li><strong>Effect Size (&eta;<sup>2</sup>):</strong> The Partial Eta Squared (&eta;<sup>2</sup>) is 0.576. According to Cohen's guidelines, this is a very large effect size, indicating that approximately 57.6% of the variance in study session scores can be explained by the study session group that individuals belonged to.</li>
            <li><strong>Descriptive Statistics:</strong>
                <ul>
                    <li>The <strong>High</strong> study session group (N=31) had a mean score of 71.71 (<i>M</i> = 4.692).</li>
                    <li>The <strong>Low</strong> study session group (N=33) had a mean score of 59.33 (<i>M</i> = 4.708).</li>
                    <li>The <strong>Medium</strong> study session group (N=36) had a mean score of 69.42 (<i>M</i> = 4.513).</li>
                </ul>
                These descriptive statistics indicate that the High group achieved the highest average score, followed by the Medium group, and then the Low group.</li>
        </ul>

        <h2>Post-hoc Tests</h2>
        <p>When there is significant difference reported by the ANOVA, it can often be useful to determine where the differences occur. For example, is there a difference between the High and the Low group, the High and the Medium group, etc.? To do this we can use post-hoc tests. These are paired comparisons for each of the groups. For the ANOVA, these pairwise comparisons are independent-samples t-test (as there are now only 2 groups). Due to running multiple tests on the same data a correction to the p-value is often made, which means the p-value will be made higher than what you would get from just the t-test. The reason for this is that the p-value in a hypothesis test is the probability of saying there is a difference when in fact one doesn&rsquo;t exist (this is why we are looking for small p-values). Running multiple tests increases the chance of making this mistake (called a Type I error), so a correction is used to reduce this chance. When there are equal variances are assumed, it is often advised to use the Tukey correction, and the Games-Howell correction when equal variances cannot be assumed.</p>

        <h3>Procedure to get Post-hoc Results in Stata.</h3>
        <p>To get post-hoc results in Stata, you can add options directly to the `oneway` command. For Tukey's HSD test, use the `tukey` option. This test is appropriate when the assumption of homogeneity of variances is met, as it is in this case. Stata automatically handles the p-value adjustment for multiple comparisons when using this option.</p>
        <p>If the assumption of homogeneity of variances is *not* met (i.e., Levene's test is significant), then a post-hoc test like <strong>Games-Howell</strong> is more appropriate. Stata does not have a built-in `gameshowell` option for `oneway`. You would typically need to install a user-written command (e.g., `ssc install gameshowell`) and then run it separately after your ANOVA if needed. Note that user-written commands often don't have direct menu equivalents or may add them to the "User-written commands" section.</p>
        <ol>
            <li>Run the `oneway` command including the `tukey` option to perform Tukey's HSD post-hoc test. The results will be displayed as part of the `oneway` command's output.
                <pre><code>oneway study_session_score study_session_group, tukey</code></pre>
                (Menu driven alternative for Tukey's HSD) Go to <strong>Statistics &gt; ANOVA/MANOVA &gt; One-way ANOVA</strong>. In the dialog box, after selecting your "Response variable" and "Factor variable", click on the "Post-hoc tests" tab. Check the box for "Tukey's HSD". Then click <strong>OK</strong>.
            </li>
            <li>(Optional) If homogeneity of variances was violated, you would instead use Games-Howell. First, install the `gameshowell` command if you haven't already, then run it.
                <pre><code>ssc install gameshowell
gameshowell study_session_score, by(study_session_group)</code></pre>
                (Menu driven alternative for Games-Howell) After installing the `gameshowell` command, you might find it under <strong>User-written commands</strong> or a similar section within the Statistics menu if its ado-file includes menu integration. Otherwise, it is primarily a command-line utility.
            </li>
        </ol>

        <div class="reflection-question">
            <h4>Question:</h4>
            <p>Which pairs of groups show significant differences between each other?</p>
        </div>

        <p>The output from `oneway study_session_score study_session_group, tukey` will look like this in your Stata Results window, including the pairwise comparisons and adjusted p-values:</p>
        <pre><code>. oneway study_session_score study_session_group, tukey

(Output showing ANOVA table, then pairwise comparisons)

      Pairwise comparisons of means (Tukey HSD)

  Group |    Mean    Std. Err.  [95% Conf. Interval]    P-value
--------+-------------------------------------------------------
   High |  71.70968   0.842797  69.98801  73.43135
    Low |  59.33333   0.820207  57.66317  61.00350
 Medium |  69.41667   0.751897  67.89201  70.94132

--------------------------------------------------------------------------
   Diff. |    High       Low    Medium
---------+----------------------------------------------------------------
     Low |  -12.376*
         | (1.159)   (0.000)
  Medium |   -2.293
         | (1.135)   (0.113)
         |
    High |    12.376* 2.293
         |  (1.159)    (1.135)
         |  (0.000)    (0.113)
---------+----------------------------------------------------------------
   (Std. Err.)   (P-value)
* significant at alpha = 0.05
--------------------------------------------------------------------------</code></pre>
        <p>The results of the post-hoc tests are summarized in the table below, structured for clarity and matching the relevant values from the Stata output:</p>
        <h4>Multiple Comparisons - Dependent Variable: study_session_score (Tukey HSD)</h4>
        <table>
            <thead>
                <tr>
                    <th rowspan="2">Comparison</th>
                    <th rowspan="2">Mean Difference (I-J)</th>
                    <th rowspan="2">Std. Error</th>
                    <th rowspan="2">Prob &gt; F</th>
                    <th colspan="2">95% Confidence Interval</th>
                </tr>
                <tr>
                    <th>Lower Bound</th>
                    <th>Upper Bound</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>High vs. Low</td>
                    <td>12.376<sup>*</sup></td>
                    <td>1.159</td>
                    <td>&lt;.001</td>
                    <td>9.62</td>
                    <td>15.13</td>
                </tr>
                <tr>
                    <td>High vs. Medium</td>
                    <td>2.293</td>
                    <td>1.135</td>
                    <td>0.113</td>
                    <td>-0.41</td>
                    <td>5.00</td>
                </tr>
                <tr>
                    <td>Low vs. Medium</td>
                    <td>-10.083<sup>*</sup></td>
                    <td>1.117</td>
                    <td>&lt;.001</td>
                    <td>-12.74</td>
                    <td>-7.43</td>
                </tr>
            </tbody>
        </table>
        <p><sup>*</sup> The mean difference is significant at the 0.05 level.</p>

        <h3>Interpretation of post-hoc results.</h3>
        <p>Here's how to interpret the key results from the Tukey Post-Hoc Test:</p>
        <ul>
            <li><strong>High vs. Low:</strong> The mean difference is 12.376, and the p-value is &lt;.001. Since <i>p</i> &lt; 0.05, there is a <strong>statistically significant difference</strong> between the High and Low study session groups. This indicates that the High group scored significantly higher on study session scores compared to the Low group.</li>
            <li><strong>High vs. Medium:</strong> The mean difference is 2.293, and the p-value is 0.113. Since <i>p</i> &gt; 0.05, there is <strong>no statistically significant difference</strong> between the High and Medium study session groups.</li>
            <li><strong>Low vs. Medium:</strong> The mean difference is -10.083, and the p-value is &lt;.001. Since <i>p</i> &lt; 0.05, there is a <strong>statistically significant difference</strong> between the Low and Medium study session groups. This indicates that the Medium group scored significantly higher on study session scores compared to the Low group.</li>
        </ul>
        <p>In summary, the Low study session group had significantly lower study session scores compared to both the High and Medium groups. There was no significant difference between the High and Medium groups.</p>

        <h2>Write-up</h2>
        <h3>Example write-up of this analysis, with post-hoc.</h3>
        <div class="write-up-template">
            <p>A one-way ANOVA was conducted to assess the effect of study session group (High, Low, Medium) on study session scores. Levene's test indicated that the assumption of homogeneity of variances was met, <i>F</i>(2, 97) = 0.160, <i>p</i> = 0.852. The ANOVA revealed a statistically significant effect of study session group on study session score, <i>F</i>(2, 97) = 65.992, <i>p</i> &lt; .001. The effect size, as measured by Eta Squared, was &eta;<sup>2</sup> = 0.576, representing a large effect, with approximately 57.6% of the variance in study session scores accounted for by the study session group.</p>
            <p>Post-hoc comparisons using Tukey's HSD test indicated that:</p>
            <ul>
                <li>The High study session group (<i>M</i> = 71.71, <i>SD</i> = 4.69) scored significantly higher than the Low group (<i>M</i> = 59.33, <i>SD</i> = 4.71), with a mean difference of 12.376, <i>p</i> &lt; .001.</li>
                <li>The Medium study session group (<i>M</i> = 69.42, <i>SD</i> = 4.51) scored significantly higher than the Low group (<i>M</i> = 59.33, <i>SD</i> = 4.71), with a mean difference of 10.083, <i>p</i> &lt; .001.</li>
                <li>There was no statistically significant difference between the High (<i>M</i> = 71.71, <i>SD</i> = 4.69) and Medium (<i>M</i> = 69.42, <i>SD</i> = 4.51) study session groups, <i>p</i> = 0.113.</li>
            </ul>
            <p>These results indicate that participation in either a High or Medium study session group leads to significantly higher study session scores compared to the Low group, while there is no significant difference in scores between the High and Medium groups themselves.</p>
        </div>
    </div>
</body>
</html>
