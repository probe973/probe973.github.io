<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>One-way ANOVA using R Studio</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        /* Merged Styles */
        body {
            font-family: 'Inter', sans-serif;
            margin: 0;
            padding: 0;
            color: #222;
            background-color: #f8f8f8;
            line-height: 1.6;
        }
        .container {
            padding: 25px;
            max-width: 960px;
            margin: 30px auto;
            background-color: white;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            border-radius: 10px;
        }
        h1 {
            color: #004085;
            border-bottom: 3px solid #004085;
            padding-bottom: 10px;
            margin-bottom: 20px;
            font-size: 2.2em;
        }
        h2 {
            color: #004085;
            margin-top: 35px;
            font-size: 1.8em;
            border-bottom: 2px solid #eee;
            padding-bottom: 5px;
        }
        h3 {
            color: #0056b3;
            font-size: 1.2em;
            border-bottom: 1px solid #eee;
            margin-top: 25px;
        }
        h4 {
            color: #0056b3;
            font-size: 1em;
            margin-top: 25px;
        }
        .subtitle {
            color: #444;
            font-size: 1.2em;
            margin-bottom: 25px;
        }
        code {
            background-color: #eef;
            padding: 2px 4px;
            border-radius: 4px;
            font-family: "Courier New", Courier, monospace;
            color: #c00;
        }
        pre {
            background-color: #eef;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: "Courier New", Courier, monospace;
            color: #333;
            border: 1px solid #ddd;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        table, th, td {
            border: 1px solid #ddd;
        }
        th, td {
            padding: 10px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
            color: #333;
            font-weight: bold;
        }
        ul {
            list-style-type: disc;
            margin-left: 20px;
        }
        ol {
            list-style-type: decimal;
            margin-left: 20px;
        }
        .reflection-question {
            background-color: #f0f8ff;
            border-left: 5px solid #add8e6;
            padding: 10px 15px;
            margin: 15px 0;
        }
        .write-up-template {
            background-color: #e9f5e9;
            border-left: 5px solid #4CAF50;
            padding: 15px;
            margin: 20px 0;
        }
        .write-up-template p {
            margin-bottom: 10px;
        }
        .solution-section {
            background-color: #f0fff0;
            border-left: 5px solid #6b8e23;
            padding: 10px 15px;
            margin: 15px 0;
        }
        .solution-section h4 {
            color: #6b8e23;
        }
        .top-nav {
            display: flex;
            justify-content: flex-start;
            gap: 15px;
            padding: 15px;
            background-color: #004085;
            border-bottom-left-radius: 10px;
            border-bottom-right-radius: 10px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            align-items: center;
            position: sticky;
            top: 0;
            width: 100%;
            z-index: 1000;
            flex-wrap: wrap;
        }
        .top-nav span {
            color: white;
            font-weight: bold;
            margin-right: 5px;
        }
        .top-nav a {
            color: white;
            padding: 8px 15px;
            border-radius: 20px;
            text-decoration: none;
            font-weight: bold;
            transition: background-color 0.3s ease, transform 0.2s ease;
            white-space: nowrap;
            background-color: rgba(255, 255, 255, 0.2);
        }
        .top-nav a:hover {
            background-color: rgba(255, 255, 255, 0.4);
            transform: translateY(-1px);
        }
        .button-group {
            display: flex;
            flex-wrap: nowrap;
            gap: 15px;
            margin-top: 20px;
            justify-content: center;
        }
        .button-group a {
            background-color: #004085;
            color: white;
            padding: 14px 25px;
            border-radius: 30px;
            text-decoration: none;
            text-align: center;
            flex-grow: 1;
            flex-basis: 0;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
            transition: background-color 0.3s ease, transform 0.2s ease;
            font-weight: bold;
            letter-spacing: 0.5px;
            white-space: nowrap;
        }
        .button-group a:hover {
            background-color: #002c5a;
            transform: translateY(-2px);
        }
        hr {
            border: 0;
            height: 2px;
            background: #e0e0e0;
            margin: 40px 0;
        }
    </style>
</head>
<body>
    <div class="top-nav">
        <span>Links to:</span>
        <a href="../index.html">Home</a>
        <a href="../r.html">R Studio Guides</a>
    </div>
    <div class="container">
        <h1>One-way ANOVA using R Studio</h1>
        <p class="subtitle">A Guide to Understanding and Performing ANOVA with R Studio</p>

        <p>ANOVA is an abbreviation of Analysis of Variance. It can be used to <strong>determine if there are statistically significant differences between the means of three or more independent (unrelated) groups on a continuous dependent variable.</strong> While it shares a goal with the independent-samples t-test (comparing means), ANOVA is specifically designed for situations with more than two groups, helping to avoid the increased risk of Type I errors that would arise from performing multiple t-tests. A one-way ANOVA is used to determine whether there are differences in a measure variable based on a single categorical factor. This factor can have more than two levels, unlike the independent-samples t-test where there could only be two. Some examples of where a one-way ANOVA could be used include:</p>
        <ul>
            <li>Comparing the effectiveness of three different teaching methods (e.g., traditional lecture, blended learning, flipped classroom) on student exam scores.</li>
            <li>Assessing if anxiety levels differ among people with mild, moderate, and severe depression.</li>
            <li>Investigating if plant growth varies significantly under three different fertilizer types.</li>
        </ul>
        <p>In this guide we will go over performing a one-way ANOVA to determine the following:</p>
        <ul>
            <li>Does preferred study method (flashcards, practice tests, summarising) make a difference to final examination score?</li>
            <li>Does study session group (low, medium, high number of sessions) make a difference to the study session score?</li>
        </ul>
        <p>You will be making using of the `omni_data` dataset, which has been used throughout all these guides. Please make sure you have downloaded the data and loaded into R Studio.</p>

        <h2>Assumptions of a One-way ANOVA</h2>
        <p>For a one-way ANOVA, there are several key assumptions that should ideally be met for the results to be reliable. It's important to check these before interpreting your ANOVA output:</p>
        <ol>
            <li><strong>Independence of Observations:</strong> The observations within each group must be independent of each other. This means that the data points in one group should not be related to or influenced by data points in another group, or within the same group. This is typically ensured by the study design (e.g., participants are randomly assigned to groups, or each participant provides only one data point).</li>
            <li><strong>Normality:</strong> The dependent variable should be approximately normally distributed for each group. While ANOVA is robust to minor violations of normality, particularly with larger sample sizes, severe non-normality can affect the validity of the p-value.
                <ul>
                    <li><strong>How to check:</strong> In R, you can assess normality using functions like `shapiro.test()` (for smaller samples) or visual inspection of histograms and Q-Q plots.</li>
                </ul>
            </li>
            <li><strong>Homogeneity of Variances (Homoscedasticity):</strong> The variance of the dependent variable should be approximately equal across all groups. This means that the spread of data points around the mean should be similar in each group.
                <ul>
                    <li><strong>How to check:</strong> The most common test for this assumption is Levene's test, which can be performed using the `leveneTest()` function from the `car` package in R.</li>
                </ul>
            </li>
        </ol>
        <p>The assumption of normality of normality has been passed for the variables we are looking at today.</p>
        <div class="reflection-question">
            <h4>Task:</h4>
            <p>Check the assumption of normality for these variables. You can use <a href="../assessing_normality_of_data/guide_r.html">this earlier guide</a> if you want to review this.</p>
        </div>

        <h2>Null and Alternative Hypotheses</h2>
        <p>The null hypothesis (H<sub>0</sub>) of a one-way ANOVA is that the mean score for all groups will be the same.</p>
        <p style="text-align: center;">H<sub>0</sub>: &#x03BC;<sub>1</sub> = &#x03BC;<sub>2</sub> = &#x03BC;<sub>3</sub> = &hellip; = &#x03BC;<sub>k</sub></p>
        <p>(where &#x03BC; represents the mean, and k is the number of groups)</p>
        <p>The alternative hypothesis (H<sub>1</sub>) is that there is a difference in the mean score between some, or all, of the groups.</p>
        <p style="text-align: center;">H<sub>1</sub>: Not all means are equal</p>
        <p>The ANOVA is carried out and produces an F statistic and a p-value. If this p-value is less than a defined amount, normally 0.05 is used, then this gives evidence of there being a difference between the groups. If this is not the case then we have not found enough evidence that the groups make a difference to the score.</p>

        <h2>One-way ANOVA procedure in R Studio for final examination score by study method</h2>
        <h3>Procedure for final examination score by study method</h3>
        <p>To conduct a One-Way ANOVA in R Studio for `final_exam_score` by `preferred_study_method`, follow these steps:</p>
        <ol>
            <li>First, ensure you have the necessary R packages installed. We'll need `car` for Levene's test, `effectsize` for calculating Eta Squared, and `PMCMRplus` if you later need to perform Games-Howell post-hoc tests (which are used when the assumption of homogeneity of variances is violated). You only need to install a package once on your system using `install.packages()`.
                <pre><code>install.packages("car")
install.packages("effectsize")
install.packages("PMCMRplus")</code></pre>
                After installation, you need to load these packages into your current R session using `library()`. This command must be run every time you start a new R session where you plan to use functions from these packages.
                <pre><code>library(car)
library(effectsize)
library(PMCMRplus)</code></pre>
            </li>

            <li>Load your `omni_data` dataset into R. Assuming your `omni.csv` file is located in your R Studio working directory, you can use the `read.csv()` function to load it. We'll store this data in a dataframe object named `omni_data`.
                <pre><code>omni_data &lt;- read.csv("omni.csv")</code></pre>
                Here, `omni_data` is the name we're assigning to our loaded dataset, and `&lt;-` is the assignment operator in R, which means "assign the result of the right side to the object on the left."
            </li>
            <li>Perform the One-Way ANOVA using the `aov()` function. This function fits an Analysis of Variance model. The formula `DependentVariable ~ IndependentVariable` specifies the relationship we want to test. In this case, `final_exam_score` is our dependent variable and `preferred_study_method` is our independent (grouping) variable. We also tell `aov()` which dataset to use with `data = omni_data`. We store the result in an object named `anova_model_1`. To view the standard ANOVA table, which includes F-value and p-value, we use the `summary()` function on our `anova_model_1` object.
                <pre><code>anova_model_1 &lt;- aov(final_exam_score ~ preferred_study_method, data = omni_data)
summary(anova_model_1)</code></pre>
            </li>
            <li>Check the homogeneity of variances using Levene's Test. We use the `leveneTest()` function from the `car` package. The syntax is `leveneTest(dependent_variable ~ grouping_variable, data = your_dataframe)`.
                <pre><code>leveneTest(final_exam_score ~ preferred_study_method, data = omni_data)</code></pre>
            </li>
            <li>To get descriptive statistics (N, Mean, Standard Deviation) for each group, you can use the `aggregate()` function. This function allows us to apply another function (in this case, calculating N, Mean, and SD) to a variable (`final_exam_score`) grouped by another variable (`preferred_study_method`).
                <pre><code>aggregate(final_exam_score ~ preferred_study_method, data = omni_data, 
          FUN = function(x) c(N = length(x), Mean = mean(x), SD = sd(x)))</code></pre>
            </li>
        </ol>

        <p>The following results are given:</p>
        <h4>Levene&rsquo;s Test for Homogeneity of Variances</h4>
        <p>The output for Levene's Test from R's `car` package will appear in your R Console. Pay attention to the `F value` and `Pr(>F)` columns.</p>
        <pre><code>Levene's Test for Homogeneity of Variance (center = mean)
      Df F value Pr(>F)
group  2   1.304  0.276
       97               </code></pre>
        <table>
            <thead>
                <tr>
                    <th></th>
                    <th>F value</th>
                    <th>Df1</th>
                    <th>Df2</th>
                    <th>Pr(&gt;F)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>final_exam_score</td>
                    <td>1.304</td>
                    <td>2</td>
                    <td>97</td>
                    <td>0.276</td>
                </tr>
            </tbody>
        </table>
        <p>Here's how to interpret these numbers:</p>
        <ul>
            <li>The <strong>F value (Levene Statistic)</strong> is 1.304.</li>
            <li>The <strong>degrees of freedom (Df1 and Df2)</strong> are 2 (representing the groups) and 97 (representing the residuals), respectively.</li>
            <li>The <strong>Pr(&gt;F) (p-value)</strong> is 0.276.</li>
        </ul>
        <p>Since the p-value for Levene&rsquo;s test (0.276) is greater than our typical alpha level of 0.05, we do not reject the null hypothesis of Levene&rsquo;s test. This indicates that <strong>the assumption of equality of variances has been met</strong>. Therefore, for the main ANOVA, you should interpret the results from the standard F-test. If the p-value had been less than 0.05 (indicating violation of homogeneity), you would typically use **Welch's ANOVA** instead of the standard ANOVA. Welch's ANOVA does not assume equal variances and is performed using `oneway.test()`, setting the `var.equal` argument to `FALSE`:</p>
        <pre><code>oneway.test(final_exam_score ~ preferred_study_method, data = omni_data, var.equal = FALSE)</code></pre>

        <h4>Descriptive Statistics</h4>
        <p>The output from the `aggregate()` function for descriptives will appear in your R Console. It organizes the data by your grouping variable and provides the calculated statistics. The table below summarizes these values for easier reading.</p>
        <table>
            <thead>
                <tr>
                    <th>preferred_study_method</th>
                    <th>N</th>
                    <th>Mean</th>
                    <th>Std. Deviation</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Flashcards</td>
                    <td>36</td>
                    <td>75.64</td>
                    <td>6.450</td>
                </tr>
                <tr>
                    <td>Practice Tests</td>
                    <td>31</td>
                    <td>74.45</td>
                    <td>5.353</td>
                </tr>
                <tr>
                    <td>Summarizing</td>
                    <td>33</td>
                    <td>73.94</td>
                    <td>5.356</td>
                </tr>
            </tbody>
        </table>
        <p>From this table, you can see the mean final exam scores for students who used Flashcards (75.64), Practice Tests (74.45), and Summarizing (73.94).</p>

        <h4>ANOVA Results</h4>
        <p>The `summary(anova_model_1)` command displays the core ANOVA table. Pay attention to the `F value` and `Pr(>F)` columns for your main effect (`preferred_study_method`).</p>
        <pre><code>              Df Sum Sq Mean Sq F value Pr(>F)
preferred_study_method  2   52.7   26.36   0.791  0.456
Residuals              97 3233.9   33.34       
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
        <table>
            <thead>
                <tr>
                    <th></th>
                    <th>Sum of Squares</th>
                    <th>df</th>
                    <th>Mean Square</th>
                    <th>F</th>
                    <th>Pr(&gt;F)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>preferred_study_method</td>
                    <td>52.728</td>
                    <td>2</td>
                    <td>26.364</td>
                    <td>0.791</td>
                    <td>0.456</td>
                </tr>
                <tr>
                    <td>Residuals</td>
                    <td>3233.862</td>
                    <td>97</td>
                    <td>33.339</td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Total</td>
                    <td>3286.590</td>
                    <td>99</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
            </tbody>
        </table>
        <p>Here's what these values mean:</p>
        <ul>
            <li><strong>F (0.791):</strong> This is the F-statistic, which is the test statistic for ANOVA.</li>
            <li><strong>df (2, 97):</strong> These are the degrees of freedom. The "df" for `preferred_study_method` (between groups) is 2, and the "df" for Residuals (within groups) is 97.</li>
            <li><strong>Pr(&gt;F) (0.456):</strong> This is the p-value associated with the F-statistic.</li>
        </ul>

        <div class="reflection-question">
            <h4>Question:</h4>
            <p>Is there evidence that the study method makes a difference to the final exam grade?</p>
            <h4>Answer:</h4>
            <p>Based on the ANOVA results, there is no statistically significant evidence that the preferred study method makes a difference to the final exam grade. The p-value obtained is 0.456, which is greater than the conventional significance level of 0.05. Therefore, we do not reject the null hypothesis, meaning we do not have sufficient evidence to conclude that there is a significant difference in final exam scores between the different study methods.</p>
        </div>

        <h2>Effect Size</h2>
        <p>Effect Size is a measure of the magnitude of the difference or relationship between variables, independent of sample size. For ANOVA, a common effect size measure is <strong>Eta Squared (&eta;<sup>2</sup>)</strong>. It represents the proportion of the total variance in the dependent variable that is accounted for by the independent variable (the grouping factor).</p>
        <ul>
            <li><strong>Interpretation of Eta Squared (&eta;<sup>2</sup>):</strong>
                <ul>
                    <li><strong>Small Effect:</strong> &eta;<sup>2</sup> = 0.01 (meaning 1% of the variance in the dependent variable is explained by the independent variable)</li>
                    <li><strong>Medium Effect:</strong> &eta;<sup>2</sup> = 0.06 (meaning 6% of the variance is explained)</li>
                    <li><strong>Large Effect:</strong> &eta;<sup>2</sup> = 0.14 (meaning 14% of the variance is explained)</li>
                </ul>
            </li>
        </ul>
        <p>In R, you can use the `eta_squared()` function from the `effectsize` package to easily compute Eta Squared from your ANOVA model object. For a one-way ANOVA, Partial Eta Squared is equivalent to Eta Squared.</p>

        <h3>Procedure to obtain Eta Squared (&eta;<sup>2</sup>) in R:</h3>
        <p>After you have run your `aov()` model and ensured the `effectsize` package is loaded, simply use the `eta_squared()` function on your model object. This will print the Eta Squared value for your `preferred_study_method` factor directly to the R Console.</p>
        <pre><code>eta_squared(anova_model_1)</code></pre>
        <h4>Effect Sizes for ANOVA (Type I)</h4>
        <p>The output from `eta_squared(anova_model_1)` will look similar to this in your R Console. The `Eta2` column provides the Eta Squared value, and `95% CI` gives the confidence interval for the effect size.</p>
        <pre><code># Effect Size for ANOVA (Type I)

Parameter              | Eta2 |       95% CI
---------------------------------------------
preferred_study_method | 0.016 | [0.00, 0.08]
Residuals              | 0.984 |             </code></pre>
        <table>
            <thead>
                <tr>
                    <th>Parameter</th>
                    <th>Eta2</th>
                    <th colspan="2">95% CI</th>
                </tr>
                <tr>
                    <th></th>
                    <th></th>
                    <th>Lower</th>
                    <th>Upper</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>preferred_study_method</td>
                    <td>0.016</td>
                    <td>0.000</td>
                    <td>0.080</td>
                </tr>
                <tr>
                    <td>Residuals</td>
                    <td>0.984</td>
                    <td></td>
                    <td></td>
                </tr>
            </tbody>
        </table>
        <p>The effect size, &eta;<sup>2</sup>, is found in the "Eta2" column for `preferred_study_method`. In this case, &eta;<sup>2</sup> = 0.016.</p>

        <div class="reflection-question">
            <h4>Question:</h4>
            <p>What is the size of the effect of study method on final examination score?</p>
            <h4>Answer:</h4>
            <p>The size of the effect of study method on final examination score, as measured by Eta Squared (&eta;<sup>2</sup>), is 0.016. According to Cohen's guidelines for interpreting effect sizes, an &eta;<sup>2</sup> of 0.01 is considered a small effect. Therefore, an &eta;<sup>2</sup> of 0.016 indicates a very small practical effect, meaning that preferred study method accounts for only 1.6% of the variance in final examination scores.</p>
        </div>

        <h2>Write-up Results</h2>
        <p>Here's an example write-up of these results:</p>
        <div class="write-up-template">
            <p>A one-way ANOVA was conducted to examine the effect of preferred study method (Flashcards, Practice Tests, Summarizing) on final examination scores. Levene's test indicated that the assumption of homogeneity of variances was met, <i>F</i>(2, 97) = 1.30, <i>p</i> = 0.276. The ANOVA results showed that there was no statistically significant effect of preferred study method on final examination score, <i>F</i>(2, 97) = 0.791, <i>p</i> = 0.456. The effect size, as measured by Eta Squared, was &eta;<sup>2</sup> = 0.016, which indicates a very small effect, accounting for only 1.6% of the variance in final examination scores. Descriptive statistics revealed that students using Flashcards had a mean score of 75.64 (<i>M</i> = 75.64, <i>SD</i> = 6.45), Practice Tests a mean of 74.45 (<i>M</i> = 74.45, <i>SD</i> = 5.35), and Summarizing a mean of 73.94 (<i>M</i> = 73.94, <i>SD</i> = 5.36).</p>
        </div>

        <hr>

        <h2>One-way ANOVA procedure in R Studio for study session score by study session group</h2>
        <h3>Procedure for study session score by study session group</h3>
        <div class="reflection-question">
            <h4>Task:</h4>
            <p>Use the previous part of the guide to conduct a one-way ANOVA to determine whether the study session group makes a difference to the study session score.</p>
        </div>
        <p>To perform this analysis in R Studio, follow the same steps as detailed for the `final_exam_score` analysis, but substitute the variables:</p>
        <ol>
            <li>Ensure the necessary packages (`car`, `effectsize`, `PMCMRplus`) are loaded and your `omni_data` dataset is loaded into R as described above.</li>
            <li>Perform the One-Way ANOVA using `aov()` and get its summary. Here, `study_session_score` is the dependent variable and `study_session_group` is the independent variable. We store this in `anova_model_2`.
                <pre><code>anova_model_2 &lt;- aov(study_session_score ~ study_session_group, data = omni_data)
summary(anova_model_2)</code></pre>
            </li>
            <li>Check the homogeneity of variances using `leveneTest()`.
                <pre><code>leveneTest(study_session_score ~ study_session_group, data = omni_data)</code></pre>
            </li>
            <li>To get descriptive statistics, use `aggregate()` for `study_session_score` grouped by `study_session_group`.
                <pre><code>aggregate(study_session_score ~ study_session_group, data = omni_data, 
          FUN = function(x) c(N = length(x), Mean = mean(x), SD = sd(x)))</code></pre>
            </li>
            <li>Obtain Eta Squared using `eta_squared()` on `anova_model_2`.
                <pre><code>eta_squared(anova_model_2)</code></pre>
            </li>
        </ol>

        <p>The results will be:</p>
        <h4>Levene&rsquo;s Test for Homogeneity of Variances</h4>
        <pre><code>Levene's Test for Homogeneity of Variance (center = mean)
      Df F value Pr(>F)
group  2   0.160  0.852
       97               </code></pre>
        <table>
            <thead>
                <tr>
                    <th></th>
                    <th>F value</th>
                    <th>Df1</th>
                    <th>Df2</th>
                    <th>Pr(&gt;F)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>study_session_score</td>
                    <td>0.160</td>
                    <td>2</td>
                    <td>97</td>
                    <td>0.852</td>
                </tr>
            </tbody>
        </table>

        <h4>ANOVA - study_session_score</h4>
        <pre><code>              Df Sum Sq Mean Sq F value   Pr(>F)    
study_session_group  2   2834    1417   65.99 1.83e-18 ***
Residuals              97   2082     21.47             
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
        <table>
            <thead>
                <tr>
                    <th></th>
                    <th>Sum of Squares</th>
                    <th>df</th>
                    <th>Mean Square</th>
                    <th>F</th>
                    <th>Pr(&gt;F)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>study_session_group</td>
                    <td>2833.530</td>
                    <td>2</td>
                    <td>1416.765</td>
                    <td>65.992</td>
                    <td>&lt;.001</td>
                </tr>
                <tr>
                    <td>Residuals</td>
                    <td>2082.470</td>
                    <td>97</td>
                    <td>21.469</td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Total</td>
                    <td>4916.000</td>
                    <td>99</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
            </tbody>
        </table>

        <h4>Descriptive Statistics</h4>
        <p>The output from the `aggregate()` function for `study_session_score` by `study_session_group` will provide the group-wise statistics. The table below summarizes these.</p>
        <table>
            <thead>
                <tr>
                    <th>study_session_group</th>
                    <th>N</th>
                    <th>Mean</th>
                    <th>Std. Deviation</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>High</td>
                    <td>31</td>
                    <td>71.71</td>
                    <td>4.692</td>
                </tr>
                <tr>
                    <td>Low</td>
                    <td>33</td>
                    <td>59.33</td>
                    <td>4.708</td>
                </tr>
                <tr>
                    <td>Medium</td>
                    <td>36</td>
                    <td>69.42</td>
                    <td>4.513</td>
                </tr>
            </tbody>
        </table>

        <h3>Interpretation of key results.</h3>
        <p>Here's an interpretation of the key results for `study_session_score` by `study_session_group`:</p>
        <ul>
            <li><strong>Homogeneity of Variances (Levene's Test):</strong> The p-value for Levene's test is 0.852. Since this value is greater than 0.05, the assumption of homogeneity of variances is met. This means you should interpret the results from the standard F-test. If the assumption had been violated, you would typically report **Welch's ANOVA** results, obtained using `oneway.test(study_session_score ~ study_session_group, data = omni_data, var.equal = FALSE)`.</li>
            <li><strong>ANOVA Results:</strong> The "ANOVA" table shows an F-statistic of 65.992 with <i>df</i>1 = 2 and <i>df</i>2 = 97, and a p-value of &lt;.001. Since the p-value is less than 0.05, there is a statistically significant effect of `study_session_group` on `study_session_score`. This indicates that there are significant differences in study session scores between at least some of the study session groups.</li>
            <li><strong>Effect Size (&eta;<sup>2</sup>):</strong> The Partial Eta Squared (&eta;<sup>2</sup>) is 0.576. According to Cohen's guidelines, this is a very large effect size, indicating that approximately 57.6% of the variance in study session scores can be explained by the study session group that individuals belonged to.</li>
            <li><strong>Descriptive Statistics:</strong>
                <ul>
                    <li>The <strong>High</strong> study session group (N=31) had a mean score of 71.71 (<i>SD</i> = 4.692).</li>
                    <li>The <strong>Low</strong> study session group (N=33) had a mean score of 59.33 (<i>SD</i> = 4.708).</li>
                    <li>The <strong>Medium</strong> study session group (N=36) had a mean score of 69.42 (<i>SD</i> = 4.513).</li>
                </ul>
                These descriptive statistics indicate that the High group achieved the highest average score, followed by the Medium group, and then the Low group.</li>
        </ul>

        <h2>Post-hoc Tests</h2>
        <p>When there is significant difference reported by the ANOVA, it can often be useful to determine where the differences occur. For example, is there a difference between the High and the Low group, the High and the Medium group, etc.? To do this we can use post-hoc tests. These are paired comparisons for each of the groups. For the ANOVA, these pairwise comparisons are independent-samples t-test (as there are now only 2 groups). Due to running multiple tests on the same data a correction to the p-value is often made, which means the p-value will be made higher than what you would get from just the t-test. The reason for this is that the p-value in a hypothesis test is the probability of saying there is a difference when in fact one doesn&rsquo;t exist (this is why we are looking for small p-values). Running multiple tests increases the chance of making this mistake (called a Type I error), so a correction is used to reduce this chance. When there are equal variances are assumed, it is often advised to use the Tukey correction, and the Games-Howell correction when equal variances cannot be assumed.</p>

        <h3>Procedure to get Post-hoc Results in R.</h3>
        <p>To get post-hoc results in R using Tukey's HSD (Honestly Significant Difference) test, you can apply the `TukeyHSD()` function to your ANOVA model object (specifically, an object created by `aov()`). This test is appropriate when the assumption of homogeneity of variances is met, as it is in this case. The `TukeyHSD()` function automatically applies a p-value adjustment to control for the increased risk of Type I errors that comes with multiple comparisons.</p>
        <p>If the assumption of homogeneity of variances is not met (i.e., Levene's test is significant), then a post-hoc test like Games-Howell is more appropriate. You can perform Games-Howell using the `gamesHowellTest()` function from the `PMCMRplus` package. Remember that `gamesHowellTest()` does not take an `aov` object directly, but rather the formula and data frame.</p>
        <ol>
            <li>Run the Tukey HSD post-hoc test on your ANOVA model (`anova_model_2`). The output, including confidence intervals and adjusted p-values, will be printed directly to your R Console.
                <pre><code>TukeyHSD(anova_model_2)</code></pre>
            </li>
            <li>(Optional) If homogeneity of variances was violated, you would instead use Games-Howell. The syntax for `gamesHowellTest()` requires specifying the formula and the data frame.
                <pre><code>gamesHowellTest(study_session_score ~ study_session_group, data = omni_data)</code></pre>
            </li>
        </ol>

        <div class="reflection-question">
            <h4>Question:</h4>
            <p>Which pairs of groups show significant differences between each other?</p>
        </div>

        <p>The output from `TukeyHSD(anova_model_2)` will look like this in your R Console:</p>
        <pre><code>  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = study_session_score ~ study_session_group, data = omni_data)

$study_session_group
                      diff        lwr        upr     p adj
Low-High           -12.376 -15.131175 -9.6208246 0.0000000
Medium-High         -2.293  -5.000966  0.4149660 0.1130000
Medium-Low          10.083   7.426175 12.7398246 0.0000000</code></pre>
        <p>The results of the post-hoc tests are summarized in the table below, reflecting the output columns from R:</p>
        <h4>Multiple Comparisons - Dependent Variable: study_session_score (Tukey HSD)</h4>
        <table>
            <thead>
                <tr>
                    <th>Comparison</th>
                    <th>Difference (diff)</th>
                    <th>Lower Bound (lwr)</th>
                    <th>Upper Bound (upr)</th>
                    <th>Adjusted P-value (p adj)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Low-High</td>
                    <td>-12.376<sup>*</sup></td>
                    <td>-15.131</td>
                    <td>-9.621</td>
                    <td>&lt;.001</td>
                </tr>
                <tr>
                    <td>Medium-High</td>
                    <td>-2.293</td>
                    <td>-5.001</td>
                    <td>0.415</td>
                    <td>0.113</td>
                </tr>
                <tr>
                    <td>Medium-Low</td>
                    <td>10.083<sup>*</sup></td>
                    <td>7.426</td>
                    <td>12.740</td>
                    <td>&lt;.001</td>
                </tr>
            </tbody>
        </table>
        <p><sup>*</sup>. The mean difference is significant at the 0.05 level (p adj &lt; 0.05).</p>

        <h3>Interpretation of post-hoc results.</h3>
        <p>Here's how to interpret the key results from the Tukey Post-Hoc Test:</p>
        <ul>
            <li><strong>Low vs. High:</strong> The mean difference is -12.376, and the adjusted p-value (`p adj`) is &lt;.001. Since <i>p</i> &lt; 0.05, there is a <strong>statistically significant difference</strong> between the Low and High study session groups. This indicates that the High group scored significantly higher on study session scores compared to the Low group.</li>
            <li><strong>Medium vs. High:</strong> The mean difference is -2.293, and the adjusted p-value (`p adj`) is 0.113. Since <i>p</i> &gt; 0.05, there is <strong>no statistically significant difference</strong> between the Medium and High study session groups.</li>
            <li><strong>Medium vs. Low:</strong> The mean difference is 10.083, and the adjusted p-value (`p adj`) is &lt;.001. Since <i>p</i> &lt; 0.05, there is a <strong>statistically significant difference</strong> between the Medium and Low study session groups. This indicates that the Medium group scored significantly higher on study session scores compared to the Low group.</li>
        </ul>
        <p>In summary, the Low study session group had significantly lower study session scores compared to both the High and Medium groups. There was no significant difference between the High and Medium groups.</p>

        <h2>Write-up</h2>
        <h3>Example write-up of this analysis, with post-hoc.</h3>
        <div class="write-up-template">
            <p>A one-way ANOVA was conducted to assess the effect of study session group (High, Low, Medium) on study session scores. Levene's test indicated that the assumption of homogeneity of variances was met, <i>F</i>(2, 97) = 0.160, <i>p</i> = 0.852. The ANOVA revealed a statistically significant effect of study session group on study session score, <i>F</i>(2, 97) = 65.992, <i>p</i> &lt; .001. The effect size, as measured by Eta Squared, was &eta;<sup>2</sup> = 0.576, representing a large effect, with approximately 57.6% of the variance in study session scores accounted for by the study session group.</p>
            <p>Post-hoc comparisons using Tukey's HSD test indicated that:</p>
            <ul>
                <li>The High study session group (<i>M</i> = 71.71, <i>SD</i> = 4.69) scored significantly higher than the Low group (<i>M</i> = 59.33, <i>SD</i> = 4.71), with a mean difference of 12.376, <i>p</i> &lt; .001.</li>
                <li>The Medium study session group (<i>M</i> = 69.42, <i>SD</i> = 4.51) scored significantly higher than the Low group (<i>M</i> = 59.33, <i>SD</i> = 4.71), with a mean difference of 10.083, <i>p</i> &lt; .001.</li>
                <li>There was no statistically significant difference between the High (<i>M</i> = 71.71, <i>SD</i> = 4.69) and Medium (<i>M</i> = 69.42, <i>SD</i> = 4.51) study session groups, <i>p</i> = 0.113.</li>
            </ul>
            <p>These results indicate that participation in either a High or Medium study session group leads to significantly higher study session scores compared to the Low group, while there is no significant difference in scores between the High and Medium groups themselves.</p>
        </div>
    </div>
</body>
</html>
